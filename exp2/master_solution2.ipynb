{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "# initialise Spark Session\n",
    "spark = SparkSession.builder.appName(\"cite\").getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse a line from the file users_libraries.txt\n",
    "# semi-colon to separate user hash with library, comma to separate the IDs in the library\n",
    "def parse_users_libraries(line):\n",
    "    if not line:\n",
    "        return\n",
    "    userHash, libraryRAW = line.split(';')\n",
    "    library = [int(doc_id) for doc_id in libraryRAW.split(',')]\n",
    "    print(library)\n",
    "    return userHash, library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse a line from the file papers_vocab.txt\n",
    "# comma to separate ID and vocab, space to separate vocabularies\n",
    "def parse_papers_count(line):\n",
    "    if not line:\n",
    "        return dict()\n",
    "    papersCountRaw = line.split(' ')\n",
    "    papersCount = dict()\n",
    "    for pcRaw in papersCountRaw:\n",
    "        paper, count = pcRaw.split(':')\n",
    "        papersCount[paper] = int(count)\n",
    "    return papersCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "citeulike_path = 'dataset/citeulike_dbis/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load authors\n",
    "authors = spark.read.csv(citeulike_path + \"authors.csv\", header=True)\n",
    "\n",
    "# load papers\n",
    "# provide schema while loading papers\n",
    "papersSchema = StructType([\n",
    "    #  name, dataType, nullable\n",
    "    StructField(\"paper_id\", IntegerType(), False),\n",
    "    StructField(\"type\", StringType(), True),\n",
    "    StructField(\"journal\", StringType(), True),\n",
    "    StructField(\"book_title\", StringType(), True),\n",
    "    StructField(\"series\", StringType(), True),\n",
    "    StructField(\"publisher\", StringType(), True),\n",
    "    StructField(\"pages\", StringType(), True),\n",
    "    StructField(\"volume\", StringType(), True),\n",
    "    StructField(\"number\", StringType(), True),\n",
    "    StructField(\"year\", StringType(), True),\n",
    "    StructField(\"month\", StringType(), True),\n",
    "    StructField(\"postedat\", StringType(), True),\n",
    "    StructField(\"address\", StringType(), True),\n",
    "    StructField(\"title\", StringType(), True),\n",
    "    StructField(\"abstract\", StringType(), True)\n",
    "])\n",
    "\n",
    "papers = spark.read.csv(citeulike_path + \"papers.csv\", header = False, schema = papersSchema)\n",
    "\n",
    "# load keywords\n",
    "keywordsSchema = StructType([\n",
    "    #  name, dataType, nullable\n",
    "    StructField(\"paper_id\", IntegerType(), False),\n",
    "    StructField(\"keyword\", StringType(), False)\n",
    "])\n",
    "\n",
    "keywords = spark.read.csv(citeulike_path + \"keywords.csv\", header=False, schema = keywordsSchema)\n",
    "\n",
    "# load papers vocabularies\n",
    "papers_vocab = sc.textFile(citeulike_path + \"papers_terms.txt\")\n",
    "# remove the header\n",
    "header = papers_vocab.first()\n",
    "papers_vocab= papers_vocab.filter(lambda line: line != header)\n",
    "\n",
    "papers_vocab = papers_vocab.map(lambda k: k.split(\",\"))\n",
    "papers_vocab = papers_vocab.map(lambda x: (int(x[0]), parse_papers_count(x[1])))\n",
    "\n",
    "papersVocSchema = StructType([\n",
    "    #  name, dataType, nullable\n",
    "    StructField(\"paper_id\", IntegerType(), False),\n",
    "    StructField(\"vocabularies\", MapType(StringType(), IntegerType(), False), True),\n",
    "])\n",
    "papers_vocab = papers_vocab.toDF(papersVocSchema)\n",
    "\n",
    "# load user libraries\n",
    "users_libraries = sc.textFile(citeulike_path + 'users_libraries.txt')\n",
    "users_libraries = users_libraries.map(parse_users_libraries)\n",
    "\n",
    "usersLibrariesSchema = StructType([\n",
    "    #  name, dataType, nullable\n",
    "    StructField(\"user_hash_id\", StringType(), False),\n",
    "    StructField(\"user_library\", ArrayType(IntegerType(), False), False),\n",
    "])\n",
    "users_libraries = users_libraries.toDF(usersLibrariesSchema)\n",
    "\n",
    "# load vocabularies\n",
    "vocabs = sc.textFile(citeulike_path + 'terms.txt')\n",
    "vocabs = vocabs.map(lambda k: k.split(\"\\t\"))\n",
    "vocabs = vocabs.toDF()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2. 1 (Advanced analysis, 10 points)\n",
    "Before developing the recommender system, you need to get more understanding about the citeulike\n",
    "dataset. This helps you to better choose, design and evaluate the suitable recommendation algorithm.\n",
    "Write a python program that uses spark to calculate the following information:\n",
    "\n",
    "## a) Examine how much missing ratings are there in the citeulike dataset by calculating the sparsity of the rating matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_count = users_libraries.withColumn('numb_ratings', F.size(\"user_library\"))\n",
    "# number of items\n",
    "num_items = papers.count()\n",
    "# number of users\n",
    "num_users = users_libraries.count()\n",
    "# number of total ratings\n",
    "num_ratings = ratings_count.selectExpr('SUM(numb_ratings)').collect()[0]['sum(numb_ratings)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 0.9998305694442852\n"
     ]
    }
   ],
   "source": [
    "sparsity = 1 - num_ratings / (num_users * num_items)\n",
    "print('Sparsity:', sparsity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Study the users’ behavior by examining the number of ratings given by the users. For that, calculate and plot the (users, number of ratings) histogram, do you notice a long tail?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9ae4f8ae80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# items ratings - Long Tail\n",
    "exploded_ratings = users_libraries.selectExpr('user_hash_id','explode(user_library) AS item')\n",
    "grouped_ratings = exploded_ratings.groupBy('item').count().selectExpr('count')\n",
    "items_ratings_count_pd = grouped_ratings.sort(F.col('count').desc()).toPandas()\n",
    "items_ratings_count_pd[:100].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) Study the papers popularity by looking at the number or ratings each paper gets. For that, calculate and plot the (items, number of ratings) histogram, do you notice a long tail here as well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwhwCZmYlzCFgZlbCHAJmZiXs/wNja/gAmIFWZAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9ae4caab70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# convert to pandas and plot\n",
    "ratings_count_pd =ratings_count.selectExpr('user_hash_id', 'numb_ratings').sort(F.col('numb_ratings').desc()).toPandas()\n",
    "ratings_count_pd.plot()\n",
    "# users ratings\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2. 2 (Rating matrix preparation, 10 points)\n",
    "Write a python program that uses spark to load users ratings from the file (users libraries.txt) into a\n",
    "DataFrame with the following columns:\n",
    "\u000f user id: a unique positive integer id for each user\n",
    "\u000f paper id: a unique positive integer id for each item\n",
    "\u000f rating: an integer value, you can use 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "import ctypes\n",
    "import sys\n",
    "\n",
    "\n",
    "# Convert string keys into int\n",
    "## Map user_hash to integer ids, produce a lookup table\n",
    "user_hashs = users_libraries.select(\"user_hash_id\").distinct()\n",
    "user_hash_id_LUT = sqlContext.createDataFrame(user_hashs.rdd.map(lambda x: x[0]).zipWithIndex(), StructType([StructField(\"user_hash_id\", StringType(), True),StructField(\"user_id\", IntegerType(), True)]))\n",
    "\n",
    "## Replace user_hash_id with user_id:\n",
    "users_libraries_with_ids = users_libraries.join(user_hash_id_LUT, users_libraries.user_hash_id == user_hash_id_LUT.user_hash_id).select('user_id','user_library')\n",
    "\"\"\"\n",
    "    The following commented code doesn't work because monotonically_increasing_id generates 64 bits numbers that use some of the first bits to indicate\n",
    "    the partition that produced them, so when there is more than one partition they are too big for ALS.\n",
    "    \n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "user_hashs = users_libraries.selectExpr(\"user_hash_id\", \"user_library\", \"row_number AS id\")\n",
    "users_libraries_with_ids = user_hashs#.withColumn(\"id\", monotonically_increasing_id())\n",
    "\"\"\"\n",
    "ratingsRDD = users_libraries_with_ids.rdd\n",
    "\n",
    "# Generate ratings (user_id, item_id,rating)\n",
    "ratings = users_libraries_with_ids.selectExpr('user_id','explode(user_library) AS item_id')\n",
    "ratings = ratings.withColumn('rating', lit(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "def generate_negatives(positives, max_size):\n",
    "    negatives = set()\n",
    "    while len(negatives) < len(positives):\n",
    "        candidate = randint(0, max_size)\n",
    "        if candidate not in positives:\n",
    "            negatives.add(candidate)\n",
    "    return list(negatives)\n",
    "\n",
    "# add the negative ratings\n",
    "ratingsRDD = users_libraries_with_ids.rdd\n",
    "ratingsRDD = ratingsRDD.map(lambda x: (x[0], x[1], generate_negatives(x[1], num_items)))\n",
    "positive_ratings = ratingsRDD.toDF().selectExpr('_1 AS user_id','explode(_2) AS item_id').withColumn('rating', lit(1))\n",
    "negative_ratings = ratingsRDD.toDF().selectExpr('_1 AS user_id','explode(_3) AS item_id').withColumn('rating', lit(0))\n",
    "ratings = positive_ratings.union(negative_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2. 3 (ALS algorithm, 10 points)\n",
    "Familiarize your self with the usage of the ALS algorithm provided by the MLlib spark library. Understand\n",
    "how to invoke it and the meaning of expected parameters. Then, write a python program that\n",
    "employs ALS to fit a model from the dataframe you generated in the last task. Use the learned model to\n",
    "generate top 10 recommendations for all users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql import Row\n",
    "\n",
    "# Configure als\n",
    "# Note we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\n",
    "#TODO: add the rank parameter\n",
    "als = ALS(maxIter = 2, rank = 20, regParam = 0.01,  userCol = 'user_id', itemCol ='item_id', ratingCol = 'rating', coldStartStrategy='drop')\n",
    "\n",
    "# fit the model\n",
    "model = als.fit(ratings)\n",
    "\n",
    "# Top 10 recommendations for each user:\n",
    "usersRecommendations = model.recommendForAllUsers(10)\n",
    "\n",
    "# Top 10 users for each paper:\n",
    "paperRecommandations = model.recommendForAllItems(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|user_id|     recommendations|\n",
      "+-------+--------------------+\n",
      "|    148|[[2439228,1.09836...|\n",
      "|    463|[[147383,2.029003...|\n",
      "|    471|[[740823,1.115332...|\n",
      "|    496|[[2932527,1.54075...|\n",
      "|    833|[[94154,1.7750247...|\n",
      "|   1088|[[87092,2.3182065...|\n",
      "|   1238|[[2771903,1.94381...|\n",
      "|   1342|[[10159910,2.0777...|\n",
      "|   1580|[[6807625,1.68559...|\n",
      "|   1591|[[484544,1.174334...|\n",
      "|   1645|[[694959,1.044573...|\n",
      "|   1829|[[347175,2.108598...|\n",
      "|   1959|[[282193,3.012484...|\n",
      "|   2122|[[1968054,2.19017...|\n",
      "|   2142|[[9951911,2.29590...|\n",
      "|   2366|[[2759277,1.80345...|\n",
      "|   2659|[[791438,2.516356...|\n",
      "|   2866|[[467090,1.855979...|\n",
      "|   3175|[[1903955,1.53665...|\n",
      "|   3749|[[527168,1.580071...|\n",
      "+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "usersRecommendations.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(user_id=15944, recommendations=[Row(item_id=105644, rating=2.867452621459961), Row(item_id=148944, rating=2.464580535888672), Row(item_id=2767438, rating=2.3786861896514893), Row(item_id=1019882, rating=2.3689022064208984), Row(item_id=258848, rating=2.315666437149048), Row(item_id=1982489, rating=2.2998735904693604), Row(item_id=239670, rating=2.292539358139038), Row(item_id=1270989, rating=2.2373573780059814), Row(item_id=1117506, rating=2.2366116046905518), Row(item_id=3829977, rating=2.234501838684082)])]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# user_id of  1eac022a97d683eace8815545ce3153f\n",
    "user_x_id = user_hash_id_LUT.filter(user_hash_id_LUT.user_hash_id == '1eac022a97d683eace8815545ce3153f').select('user_id').collect()[0]['user_id']\n",
    "\n",
    "usersRecommendations.filter(usersRecommendations.user_id == user_x_id).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2. 4 (Recommender system Evaluation, 10 points)\n",
    "Spark MLlib provides functionality for evaluating machine learning algorithms. Write the python program\n",
    "that uses spark to evaluate your ALS-base recommender that you built in the previous task on a\n",
    "held-out test data following the following steps:\n",
    "\n",
    "## a) Split the rating matrix into two sets: training set (contains 70% of the ratings) and test set (with 30%of the ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "training, test = ratings.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Fit a model on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = als.fit(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) Calculate the Root Mean Squared Error (RMSE) over the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 0.3701241122812283\n"
     ]
    }
   ],
   "source": [
    "# Evaluate based on RMSE:\n",
    "predictions = model.transform(test)\n",
    "evaluator = RegressionEvaluator(metricName = \"rmse\", labelCol = \"rating\", predictionCol = \"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"RMSE = {}\".format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d) Generate top 10 recommendations over the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 recommendations for each user based on the predictions of the test dataset:\n",
      "+-------+-------+------+----------+----+\n",
      "|user_id|item_id|rating|prediction|rank|\n",
      "+-------+-------+------+----------+----+\n",
      "|     26|3468922|     1| 1.0610949|   1|\n",
      "|     26|6864015|     1|0.77888405|   2|\n",
      "|     26| 845121|     1| 0.6822828|   3|\n",
      "|     26|6806660|     1|0.65059996|   4|\n",
      "|     26|6563754|     1|0.53402793|   5|\n",
      "|     26|5489845|     1|0.51439255|   6|\n",
      "|     26| 989887|     1| 0.5112466|   7|\n",
      "|     26|1693077|     1| 0.5084427|   8|\n",
      "|     26|4267226|     1|0.46791676|   9|\n",
      "|     26|2729436|     1|0.40642715|  10|\n",
      "|     29|2341475|     1|0.95613927|   1|\n",
      "|     29|2353399|     1| 0.8916104|   2|\n",
      "|     29|1376607|     1| 0.8763686|   3|\n",
      "|     29|2353164|     1| 0.8462488|   4|\n",
      "|     29|3048710|     1|0.47668642|   5|\n",
      "|     29| 950558|     1|0.32409856|   6|\n",
      "|     29| 514565|     1|0.31706372|   7|\n",
      "|     29|2882226|     1|0.28870162|   8|\n",
      "|     29|7415951|     1| 0.1830913|   9|\n",
      "|     29|5375052|     1|0.15965022|  10|\n",
      "+-------+-------+------+----------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# a) learned model over the test set -> predictions from previous cell\n",
    "# b) For each user, order the papers by the predicted ratings descendingly.\n",
    "# c) Choose the top 10 papers to be the recommendations for that user.\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import rank, col\n",
    "\n",
    "window = Window.partitionBy(predictions['user_id']).orderBy(predictions['prediction'].desc())\n",
    "\n",
    "top10Predictions = predictions.select('*', rank().over(window).alias('rank')).filter(col('rank') <= 10)\n",
    "\n",
    "print(\"Top 10 recommendations for each user based on the predictions of the test dataset:\")\n",
    "top10Predictions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2. 5 (Hyperparameter tuning, 10 points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important parameters:\n",
    "+ <b>rank</b>: is the number of features to use (also referred to as the number of latent factors).\n",
    "+ <b>maxIter</b>: iterations is the number of iterations of ALS to run.\n",
    "+ <b>regParam</b>: specifies the regularization parameter in ALS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "evaluator = RegressionEvaluator(metricName = \"rmse\", labelCol = \"rating\", predictionCol = \"prediction\")\n",
    "als = ALS(maxIter = 2, rank = 20, regParam = 0.01,  userCol = 'user_id', itemCol ='item_id', ratingCol = 'rating', coldStartStrategy='drop')\n",
    "\n",
    "params = ParamGridBuilder() \\\n",
    "    .baseOn([als.predictionCol, 'prediction']) \\\n",
    "    .addGrid(als.rank, [10, 25, 50]) \\\n",
    "    .build()\n",
    "#.addGrid(als.regParam, [0.01 * i for i in range(1,100)]) \\\n",
    "    #.addGrid(als.maxIter, [1, 2, 3, 4]) \\\n",
    "cv= CrossValidator(estimator=als, estimatorParamMaps=params, evaluator=evaluator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for the whole computation: 283 seconds \n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "t_initial=datetime.now()\n",
    "cv_model = cv.fit(training)\n",
    "time_taken=datetime.now()-t_initial\n",
    "print(\"Time taken for the whole computation: {0} seconds \".format(str(time_taken.seconds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model is for the value of rank: 50\n",
      "The RMSE value for the selected model is: 0.5877320574382847\n"
     ]
    }
   ],
   "source": [
    "best_model = cv_model.bestModel\n",
    "print(\"The best model is for the value of rank:\", best_model.rank)\n",
    "prediction = best_model.transform(test)\n",
    "rmse = evaluator.evaluate(prediction)\n",
    "print(\"The RMSE value for the selected model is:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try to increase the maxIter, do you get better results? Report your observation.\n",
    "### The results after increasing the maxIter parameter did not get any better.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLD d) For each of the following metrics, write one function that calculates the metric’s value. The metrics should report the average value over all users:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "Recall@k = \\frac{1}{\\text{Number of Users}}\\ \\sum_{u \\in users} \\frac{\\text{Number of papers the user u likes in top k}}{\\text{Total number of papers the user u likes}}\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# users_ratings - each row [user_id, user_library = [,,,]]\n",
    "# top_k_recommendations - each row [user_id, top_recommended_items = [,,,,]]\n",
    "\n",
    "def recall_k(users_ratings, top_k_recommendations):\n",
    "    total_number_of_users = users_ratings.count()\n",
    "    # user_id, count of liked papers per user\n",
    "    total_number_of_papers_per_user = users_ratings.select(users_ratings.user_id, F.size(users_ratings.user_library).alias(\"liked_papers_count\")) \n",
    "    \n",
    "    # user_id, top_recommended_items, user_library\n",
    "    recommendations_ratings = top_k_recommendations.join(users_ratings, top_k_recommendations.user_id == users_ratings.user_id)\\\n",
    "        .select(top_k_recommendations.user_id, top_k_recommendations.top_recommended_items, users_ratings.user_library) \n",
    "\n",
    "    liked_papers_in_top_k_schema = StructType([\n",
    "        #  name, dataType, nullable\n",
    "        StructField(\"user_id\", IntegerType(), False),\n",
    "        StructField(\"papers_count\", IntegerType(), False),\n",
    "    ])\n",
    "    # user_id, count of papers the user u likes in top k\n",
    "    #TODO: check len(set)\n",
    "    \n",
    "    liked_papers_in_top_k_per_user = recommendations_ratings.rdd.map(lambda row: (row[0], len(set(row[1]) & set(row[2])))).toDF(liked_papers_in_top_k_schema)\n",
    "    #TODO: unneded join - replace with add len(row[1]) to the previous RDD\n",
    "    recallDF = liked_papers_in_top_k_per_user.join(total_number_of_papers_per_user, liked_papers_in_top_k_per_user.user_id == total_number_of_papers_per_user.user_id)\\\n",
    "        .select(liked_papers_in_top_k_per_user.papers_count, total_number_of_papers_per_user.liked_papers_count)\n",
    "    sum_over_all_users = recallDF.rdd.map(lambda row : (row[0] / row[1])).sum()\n",
    "    return (1 / total_number_of_users) * sum_over_all_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\\begin{align}\n",
    "MRR@k = \\frac{1}{\\text{Number of Users}}\\ \\sum_{u \\in users} \\frac{1}{p_u}\\\n",
    "\\end{align}\n",
    "Where $p_u$ is the position of the first hit in the list of top k recommended papers. For example: given\n",
    "the user’s u library: $\\{$ 7, 12, 19, 66, 10 $\\}$ assume the algorithm produces the following top 10 items\n",
    "ids as recommendation for user u: $\\{$ 3, 4, 5, 7, 12, 43, 2, 10, 66, 19$\\}$. Then: $p_u$ = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO add comments\n",
    "\n",
    "# TODO ask about if no common elements\n",
    "def one_over_first_common_element_index(searched_array, searching_array):\n",
    "    set_searched = set(searched_array)\n",
    "    first_commom_element = next((a for a in searching_array if a in set_searched), -1) \n",
    "    if first_commom_element ==  -1:\n",
    "        return 0\n",
    "    else:\n",
    "        return (1/(searched_array.index(first_commom_element) + 1))\n",
    "    \n",
    "def mrr_k(users_ratings, top_k_recommendations):\n",
    "    total_number_of_users = users_ratings.count()\n",
    "\n",
    "    # top_recommended_items, user_library\n",
    "    recommendations_ratings = top_k_recommendations.join(users_ratings, top_k_recommendations.user_id == \\\n",
    "                                               users_ratings.user_id).select(top_k_recommendations.top_recommended_items, users_ratings.user_library) \n",
    "    # 1 / p_u calculation\n",
    "    sum_p_per_user = recommendations_ratings.rdd.map(lambda row: one_over_first_common_element_index(row[0], row[1])).sum()\n",
    "    return (1 / total_number_of_users) * sum_p_per_user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLD d) e) Calculate and report:\n",
    "* MRR@5 and MRR@10\n",
    "* Recall@k for k [10, 20, 40, 60, 80, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MRR@5 calculation\n",
    "\n",
    "# fit the model over all data\n",
    "mrr_model = als.fit(ratings) \n",
    "\n",
    "# [Row(user_id=148, recommendations=[Row(item_id=4044418, rating=1.5029594898223877) ...)\n",
    "usersRecommendations = mrr_model.recommendForAllUsers(5)\n",
    "# tranformation of user recommnedation\n",
    "top_5_recommendations = usersRecommendations.selectExpr('user_id','recommendations.item_id AS top_recommended_items')\n",
    "\n",
    "# users_libraries_with_ids - each row [user_id, user_library = [,,,]]\n",
    "# top_5_recommendations - each row [user_id, top_recommended_items = [,,,,]]\n",
    "mrr_5 = mrr_k(users_libraries_with_ids, top_5_recommendations)\n",
    "print(mrr_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MRR@10 calculation\n",
    "\n",
    "# [Row(user_id=148, recommendations=[Row(item_id=4044418, rating=1.5029594898223877) ...)\n",
    "usersRecommendations = mrr_model.recommendForAllUsers(10)\n",
    "# tranformation of user recommnedation\n",
    "top_10_recommendations = usersRecommendations.selectExpr('user_id','recommendations.item_id AS top_recommended_items')\n",
    "\n",
    "# users_libraries_with_ids - each row [user_id, user_library = [,,,]]\n",
    "# top_5_recommendations - each row [user_id, top_recommended_items = [,,,,]]\n",
    "mrr_10 = mrr_k(users_libraries_with_ids, top_10_recommendations)\n",
    "print(mrr_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Recall@10 calculation\n",
    "\n",
    "#TODO split training and transform test \n",
    "\n",
    "# fit the model over all data\n",
    "recall_model = als.fit(ratings)\n",
    "\n",
    "# [Row(user_id=148, recommendations=[Row(item_id=4044418, rating=1.5029594898223877) ...)\n",
    "usersRecommendations = recall_model.recommendForAllUsers(10)\n",
    "\n",
    "# tranformation of user recommnedation\n",
    "top_10_users_recommendations = usersRecommendations.selectExpr('user_id','recommendations.item_id AS top_recommended_items')\n",
    "\n",
    "# users_libraries_with_ids - each row [user_id, user_library = [,,,]]\n",
    "# top_10_users_recommendations - each row [user_id, top_recommended_items = [,,,,]]\n",
    "recall_10 = recall_k(users_libraries_with_ids, top_10_users_recommendations)\n",
    "print(recall_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recall_10.filter(F.col('paper_count') == 0).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Recall@20 calculation\n",
    "\n",
    "# [Row(user_id=148, recommendations=[Row(item_id=4044418, rating=1.5029594898223877) ...)\n",
    "usersRecommendations = model.recommendForAllUsers(20)\n",
    "\n",
    "# tranformation of user recommnedation\n",
    "top_20_users_recommendations = usersRecommendations.selectExpr('user_id','recommendations.item_id AS top_recommended_items')\n",
    "\n",
    "# users_libraries_with_ids - each row [user_id, user_library = [,,,]]\n",
    "# top_20_users_recommendations - each row [user_id, top_recommended_items = [,,,,]]\n",
    "recall20 = recall_k(users_libraries_with_ids, top_20_users_recommendations)\n",
    "print(recall20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Recall@40 calculation\n",
    "\n",
    "usersRecommendations = model.recommendForAllUsers(40)\n",
    "\n",
    "# tranformation of user recommnedation\n",
    "top_40_users_recommendations = usersRecommendations.selectExpr('user_id','recommendations.item_id AS top_recommended_items')\n",
    "\n",
    "# users_libraries_with_ids - each row [user_id, user_library = [,,,]]\n",
    "# top_20_users_recommendations - each row [user_id, top_recommended_items = [,,,,]]\n",
    "recall40 = recall_k(users_libraries_with_ids, top_40_users_recommendations)\n",
    "print(recall40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Recall@60 calculation\n",
    "usersRecommendations = model.recommendForAllUsers(60)\n",
    "\n",
    "# tranformation of user recommnedation\n",
    "top_60_users_recommendations = usersRecommendations.selectExpr('user_id','recommendations.item_id AS top_recommended_items')\n",
    "\n",
    "# users_libraries_with_ids - each row [user_id, user_library = [,,,]]\n",
    "# top_20_users_recommendations - each row [user_id, top_recommended_items = [,,,,]]\n",
    "recall60 = recall_k(users_libraries_with_ids, top_60_users_recommendations)\n",
    "print(recall60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Recall@80 calculation\n",
    "usersRecommendations = model.recommendForAllUsers(80)\n",
    "\n",
    "# tranformation of user recommnedation\n",
    "top_80_users_recommendations = usersRecommendations.selectExpr('user_id','recommendations.item_id AS top_recommended_items')\n",
    "\n",
    "# users_libraries_with_ids - each row [user_id, user_library = [,,,]]\n",
    "# top_20_users_recommendations - each row [user_id, top_recommended_items = [,,,,]]\n",
    "recall80 = recall_k(users_libraries_with_ids, top_80_users_recommendations)\n",
    "print(recall80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Recall@100 calculation\n",
    "usersRecommendations = model.recommendForAllUsers(100)\n",
    "\n",
    "# tranformation of user recommnedation\n",
    "top_100_users_recommendations = usersRecommendations.selectExpr('user_id','recommendations.item_id AS top_recommended_items')\n",
    "\n",
    "# users_libraries_with_ids - each row [user_id, user_library = [,,,]]\n",
    "# top_20_users_recommendations - each row [user_id, top_recommended_items = [,,,,]]\n",
    "recall100 = recall_k(users_libraries_with_ids, top_100_users_recommendations)\n",
    "print(recall100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
