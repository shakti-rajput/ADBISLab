{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0a96e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext,SparkConf\n",
    "from pyspark.sql import SparkSession,SQLContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import Row\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.ml.feature import StopWordsRemover, RegexTokenizer,HashingTF\n",
    "from pyspark.ml import Pipeline\n",
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.mllib.clustering import LDA\n",
    "from pyspark.ml.feature import IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e28eea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise Spark Session\n",
    "spark = SparkSession.builder.appName(\"Experiment3\").getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10e53038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#Keywords dataframe\\n\\nkeywordsSchema = StructType([\\n    StructField(\"paper_id\",StringType(),False),\\n    StructField(\"keyword\",StringType(),False)\\n])\\n\\ndf_keywords = spark.read.csv(\"Datasets/keywords.csv\", sep = \",\", header = True, schema = keywordsSchema, quote = \\'\"\\')\\n\\n#Terms Dataframe\\nterms_df = spark.read.csv(\"Datasets/terms.txt\", header = True)\\n\\n#Stopword Broadcast\\nstopWords = sc.textFile(\"Datasets/stopwords_en.txt\")\\nstopWordsBroadcast = sc.broadcast(stopWords.collect())\\n\\n#Papers Terms Dataframe\\ndef parse_papers_count(line):\\n\\n    if not line:\\n        return dict()\\n    papers_count_raw = line.split(\\' \\')\\n    papers_count = dict()\\n    for pcRaw in papers_count_raw:\\n        paper, count = pcRaw.split(\\':\\')\\n        papers_count[paper] = int(count)\\n    return papers_count\\n\\npapers_vocab = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"Datasets/papers_terms.txt\").rdd\\npapers_vocab = papers_vocab.map(lambda x: (x[0], parse_papers_count(x[1]))).toDF().selectExpr(\\'_1 AS paper_id\\',\\'_2 AS term_count\\')    \\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PREPARING DATAFRAMES FOR DATSETS\n",
    "\n",
    "#Authors Dataframe\n",
    "#df_authors = spark.read.csv(\"Datasets/authors.csv\", sep = \",\", header = True, quote = '\"')\n",
    "\n",
    "#PaperCsv dataframe\n",
    "papersCsvSchema = StructType([\n",
    "    StructField(\"paper_id\",StringType(),False),\n",
    "    StructField(\"type\",StringType(),False),\n",
    "    StructField(\"journal\",StringType(),False),\n",
    "    StructField(\"book_title\",StringType(),False),\n",
    "    StructField(\"series\",StringType(),False),\n",
    "    StructField(\"publisher\",StringType(),False),\n",
    "    StructField(\"pages\",StringType(),False),\n",
    "    StructField(\"volume\",StringType(),False),\n",
    "    StructField(\"number\",StringType(),False),\n",
    "    StructField(\"year\",StringType(),False),\n",
    "    StructField(\"month\",StringType(),False),\n",
    "    StructField(\"postedat\",StringType(),False),\n",
    "    StructField(\"address\",StringType(),False),\n",
    "    StructField(\"title\",StringType(),False),\n",
    "    StructField(\"abstract\",StringType(),False),\n",
    "])\n",
    "df_paperCsv = spark.read.csv(\"Datasets/papers.csv\", sep = \",\", header = False, schema = papersCsvSchema, quote = '\"')\n",
    "\n",
    "#UserLibrary dataframe\n",
    "userLibrarySchema = StructType([\n",
    "    StructField(\"user_hash_id\",StringType(),False),\n",
    "    StructField(\"user_library\",StringType(),False)\n",
    "])\n",
    "df_userLibrary = spark.read.csv(\"Datasets/users_libraries.txt\", sep = \";\", header = False, schema = userLibrarySchema)\n",
    "df_userLibrary = df_userLibrary.selectExpr(\"user_hash_id\",\"split(user_library,',') AS user_library\")\n",
    "\n",
    "\"\"\"\n",
    "#Keywords dataframe\n",
    "\n",
    "keywordsSchema = StructType([\n",
    "    StructField(\"paper_id\",StringType(),False),\n",
    "    StructField(\"keyword\",StringType(),False)\n",
    "])\n",
    "\n",
    "df_keywords = spark.read.csv(\"Datasets/keywords.csv\", sep = \",\", header = True, schema = keywordsSchema, quote = '\"')\n",
    "\n",
    "#Terms Dataframe\n",
    "terms_df = spark.read.csv(\"Datasets/terms.txt\", header = True)\n",
    "\n",
    "#Stopword Broadcast\n",
    "stopWords = sc.textFile(\"Datasets/stopwords_en.txt\")\n",
    "stopWordsBroadcast = sc.broadcast(stopWords.collect())\n",
    "\n",
    "#Papers Terms Dataframe\n",
    "def parse_papers_count(line):\n",
    "\n",
    "    if not line:\n",
    "        return dict()\n",
    "    papers_count_raw = line.split(' ')\n",
    "    papers_count = dict()\n",
    "    for pcRaw in papers_count_raw:\n",
    "        paper, count = pcRaw.split(':')\n",
    "        papers_count[paper] = int(count)\n",
    "    return papers_count\n",
    "\n",
    "papers_vocab = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"Datasets/papers_terms.txt\").rdd\n",
    "papers_vocab = papers_vocab.map(lambda x: (x[0], parse_papers_count(x[1]))).toDF().selectExpr('_1 AS paper_id','_2 AS term_count')    \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e41c0a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning and Tokenizing the data\n",
    "def phraseTokenization(x):\n",
    "    rawPhrase = x[13] + \" \" + x[14] #concatenating title and abstract\n",
    "    rawPhrase = rawPhrase.replace(\"-\",\"\") #removing - from phrase\n",
    "    rawPhrase = rawPhrase.replace(\"_\",\"\") #removing _ from phrase\n",
    "    rawPhrase = rawPhrase.strip() #removing any trailing or leading whitespaces\n",
    "    \n",
    "    #spliting phrase based on non-alphaNumeric characters\n",
    "    phraseArray = re.split('[^a-zA-Z0-9]+',rawPhrase) \n",
    "    \n",
    "    #remove words with less than 3 char\n",
    "    phraseArrayFilteredWords = [i for i in phraseArray if len(i) >= 3]\n",
    "    \n",
    "    return (x[0],list(phraseArrayFilteredWords))\n",
    "\n",
    "\n",
    "df_tokenize = df_paperCsv.na.fill(value=\"\").rdd.map(phraseTokenization).toDF()\n",
    "\n",
    "#Removing StopWords using ML\n",
    "swRemover = StopWordsRemover(inputCol=\"_2\", outputCol=\"cleaned_terms\")\n",
    "df_cleanedData = swRemover.transform(df_tokenize)\n",
    "df_cleanedData = df_cleanedData.selectExpr(\"_1 AS paper_id\",\"cleaned_terms\")\n",
    "\n",
    "#Stemming using Porter stemmer Algo\n",
    "ps =  PorterStemmer()\n",
    "\n",
    "def stemmingTerms(x):\n",
    "    stemmedWords = []\n",
    "    for word in x:\n",
    "        rootWord = ps.stem(word)\n",
    "        stemmedWords.append(rootWord)\n",
    "    return stemmedWords\n",
    "\n",
    "df_cleanedData = df_cleanedData.rdd.mapValues(stemmingTerms).toDF().selectExpr(\"_1 AS paper_id\",\"_2 AS cleaned_terms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71118f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the count of papers in which the term is present\n",
    "df_paperCount = df_cleanedData.selectExpr(\"paper_id\",\"explode(cleaned_terms) AS terms\").distinct().groupBy(\"terms\").count().withColumnRenamed(\"count\", \"paper_count\")\n",
    "\n",
    "#10 percent of total papers present in file\n",
    "noOfDistinctPapers_df = int(df_cleanedData.select(countDistinct(\"paper_id\")).collect()[0][0])\n",
    "tenPercentOfTotalPapers = int(noOfDistinctPapers_df/10)\n",
    "\n",
    "# remove words appear in more than 10% of the papers and keep only the words that appear in at least 20 papers \n",
    "df_filterdTerms = df_paperCount.filter((df_paperCount[\"paper_count\"]<=tenPercentOfTotalPapers) & (df_paperCount[\"paper_count\"]>=20))\n",
    "\n",
    "#Fetch top 1000 terms \n",
    "top1000Terms = df_filterdTerms.orderBy(col(\"paper_count\").desc()).limit(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8621d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#associate unique integer values to each term\n",
    "df_termsWithUniqueIndex = top1000Terms.withColumn(\"unique_index\",row_number().over(Window.orderBy(\"paper_count\"))).selectExpr(\"terms\",\"unique_index-1 AS unique_index\")\n",
    "\n",
    "#Collect all terms in a list\n",
    "terms_collection =  [row.terms for row in df_termsWithUniqueIndex.collect()]\n",
    "\n",
    "# Generating Termfrequency Vector for each paper\n",
    "df_cleanedDataExplode = df_cleanedData.selectExpr(\"paper_id\",\"explode(cleaned_terms) AS terms\")\n",
    "\n",
    "#Getting the Unique_index of term \n",
    "df_cleanedDataJoinIndex = df_cleanedDataExplode.join(df_termsWithUniqueIndex,df_cleanedDataExplode.terms == df_termsWithUniqueIndex.terms , how = \"inner\").select(df_cleanedDataExplode.paper_id,df_cleanedDataExplode.terms,df_termsWithUniqueIndex.unique_index)\n",
    "\n",
    "#Getting the term_frequency in each paper\n",
    "df_cleanedDataJoinIndex = df_cleanedDataJoinIndex.groupBy(\"paper_id\",\"unique_index\").count().withColumnRenamed(\"count\", \"term_frquency\")\n",
    "\n",
    "#Creating a sparseVector respresentation for each paper\n",
    "rdd_CleanedDataReducedByPaperId = df_cleanedDataJoinIndex.rdd.map(lambda x: (x[0], [(x[1], x[2])])).reduceByKey(lambda a, b: a + b)\n",
    "rdd_CleanedDataReducedByPaperId = rdd_CleanedDataReducedByPaperId.map(lambda x: (x[0],Vectors.sparse(1000,x[1])))\n",
    "\n",
    "df_CleanedDataSparseVector = rdd_CleanedDataReducedByPaperId.toDF().selectExpr(\"_1 AS paper_id\",\"_2 AS term_frequency_vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b89110e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(paper_id='498902', term_frequency_vector=SparseVector(1000, {33: 3.0, 47: 1.0, 79: 1.0, 97: 1.0, 138: 1.0, 170: 6.0, 354: 1.0, 368: 1.0, 394: 1.0, 482: 2.0, 491: 1.0, 541: 1.0, 550: 1.0, 566: 1.0, 581: 1.0, 596: 1.0, 622: 1.0, 632: 1.0, 663: 1.0, 670: 1.0, 720: 2.0, 723: 1.0, 762: 1.0, 764: 1.0, 773: 1.0, 797: 1.0, 820: 1.0, 826: 1.0, 837: 2.0, 843: 1.0, 879: 1.0, 881: 1.0, 890: 1.0, 892: 1.0, 894: 1.0, 928: 1.0, 937: 1.0, 946: 2.0, 949: 3.0, 952: 1.0, 962: 1.0, 965: 1.0, 984: 1.0, 985: 4.0, 990: 1.0, 992: 1.0}))]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_CleanedDataSparseVector.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e81d6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF Representation for each paper\n",
    "\n",
    "idf = IDF(inputCol=\"term_frequency_vector\", outputCol=\"tf_idf_vector\")\n",
    "tf_idf_model = idf.fit(df_CleanedDataSparseVector)\n",
    "df_rescaledCleanedData = tf_idf_model.transform(df_CleanedDataSparseVector)\n",
    "df_rescaledCleanedData = df_rescaledCleanedData.select(\"paper_id\", \"tf_idf_vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a942aa94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|paper_id|tf_idf_vector                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |\n",
      "+--------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|498902  |(1000,[33,47,79,97,138,170,354,368,394,482,491,541,550,566,581,596,622,632,663,670,720,723,762,764,773,797,820,826,837,843,879,881,890,892,894,928,937,946,949,952,962,965,984,985,990,992],[13.843865214712604,4.595985791629411,4.549438703969393,4.5325273651982325,4.486642746262863,26.647438178894333,4.152155546176806,4.1302347893768445,4.084564752543656,7.805081718189318,3.8889392301233388,3.79831227290147,3.783402518535183,3.757061185905204,3.7152204055042612,3.698573754270871,3.648385707492325,3.625558877507462,3.5657709591284887,3.5395447628334096,6.787125456660198,3.3874966972404748,3.2928658982552155,3.291733853175963,3.2717315861812413,3.2131219656063092,3.148751544656846,3.130565439222316,6.152952993058573,3.0650729778528127,2.958823796487294,2.951551037158214,2.90755946787668,2.9042627615941883,2.89552431166853,2.739278415151143,2.6945274051449313,5.245928315760445,7.8223034760430865,2.591339680596422,2.5231173241084237,2.5147590664942223,2.3717325419052724,9.458432887176425,2.328000775219262,2.3176958321607275])                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n",
      "|201593  |(1000,[38,90,104,110,202,251,286,327,337,412,427,448,459,485,509,528,542,584,585,622,645,666,668,685,716,729,739,756,759,763,776,778,784,791,803,806,816,828,833,844,860,865,866,868,869,872,895,907,911,913,915,917,919,921,926,927,944,947,957,965,966,970,976,978,984,987,995,996,998],[4.608572113011712,4.540947285837427,4.52362357793997,4.51534766863611,8.79659500439076,4.3157764785073764,4.267457901236568,4.186755693440204,4.178483044330837,4.055005950302112,4.019914630490842,3.9760307064361724,3.961715208265994,7.792616920459774,3.8528862987796093,3.8296457175593113,15.188959546958868,3.7117704267250407,3.711278542799727,3.648385707492325,3.5966422719952513,3.5608934179137153,3.556460692977393,3.4993607850143764,3.406349935434521,3.3710898724780405,3.3544314966318463,6.626929918250576,6.598718855131527,3.292380579148383,6.536820224381042,3.261800078680325,6.4949436945207175,6.460602823241907,3.203605165154777,6.371131035559125,3.1531039558800567,3.120164360098974,3.08643073720373,3.0626278315345146,3.022814057179705,3.00919672107724,2.997206024516253,2.9949211338583073,5.984324361019721,2.982268780784276,5.787137279196039,2.7949386358376618,2.788273251427272,2.7762319328934777,2.7692103102389822,2.7677735971907396,2.7599558435789304,2.757110891446699,2.7480610559267813,2.7410474207798243,5.315353988917025,2.618667340824799,2.565989780700896,2.5147590664942223,5.011613970213341,2.4754840467573977,2.4285840974601967,2.422263350552488,4.743465083810545,2.3556309864494978,13.766840042497792,4.560177723543891,4.550328374916718])|\n",
      "+--------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_rescaledCleanedData.limit(2).show(truncate =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc99f8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg import Vectors as MLlibVectors\n",
    "\n",
    "# Latent Direchlet Allocation\n",
    "\n",
    "num_topics = 40\n",
    "\n",
    "# Transform data into LDA supported format\n",
    "rdd_lda_format = df_CleanedDataSparseVector.rdd.mapValues(MLlibVectors.fromML).map(lambda x: [int(x[0]),x[1]])\n",
    "\n",
    "#Train the LDA Model\n",
    "lda_model = LDA.train(rdd_lda_format, k=num_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe752359",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the top 5 term of each extracted Topic\n",
    "topicIndices = sc.parallelize(lda_model.describeTopics(maxTermsPerTopic = 5))\n",
    "\n",
    "def Get_TopicTerms(topic):\n",
    "    termsId_array = topic[0] \n",
    "    terms_array = []\n",
    "    \n",
    "    #Finding the term from the their corresponding Unique index\n",
    "    for i in range(5):\n",
    "        term = terms_collection[termsId_array[i]]\n",
    "        terms_array.append(term)\n",
    "    return terms_array\n",
    "\n",
    "topics_Final = topicIndices.map(Get_TopicTerms).collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51301aa0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['gene', 'network', 'protein', 'cell', 'interact'],\n",
       " ['gene', 'protein', 'cell', 'network', 'activ'],\n",
       " ['gene', 'protein', 'network', 'cell', 'activ'],\n",
       " ['gene', 'protein', 'network', 'sequenc', 'cell'],\n",
       " ['network', 'gene', 'protein', 'interact', 'activ'],\n",
       " ['gene', 'network', 'cell', 'protein', 'activ'],\n",
       " ['network', 'gene', 'protein', 'activ', 'cell'],\n",
       " ['network', 'gene', 'protein', 'activ', 'cell'],\n",
       " ['gene', 'protein', 'network', 'sequenc', 'interact'],\n",
       " ['network', 'gene', 'protein', 'sequenc', 'interact'],\n",
       " ['gene', 'protein', 'cell', 'network', 'activ'],\n",
       " ['gene', 'protein', 'cell', 'network', 'sequenc'],\n",
       " ['gene', 'network', 'protein', 'cell', 'activ'],\n",
       " ['gene', 'network', 'protein', 'cell', 'activ'],\n",
       " ['gene', 'protein', 'cell', 'network', 'sequenc'],\n",
       " ['network', 'gene', 'protein', 'interact', 'activ'],\n",
       " ['gene', 'protein', 'network', 'cell', 'sequenc'],\n",
       " ['gene', 'protein', 'network', 'cell', 'activ'],\n",
       " ['gene', 'network', 'protein', 'activ', 'interact'],\n",
       " ['gene', 'cell', 'protein', 'network', 'activ'],\n",
       " ['network', 'gene', 'protein', 'activ', 'interact'],\n",
       " ['gene', 'network', 'protein', 'cell', 'sequenc'],\n",
       " ['gene', 'protein', 'network', 'sequenc', 'interact'],\n",
       " ['gene', 'network', 'protein', 'interact', 'activ'],\n",
       " ['network', 'protein', 'gene', 'interact', 'sequenc'],\n",
       " ['gene', 'protein', 'network', 'cell', 'activ'],\n",
       " ['network', 'protein', 'gene', 'interact', 'activ'],\n",
       " ['gene', 'protein', 'network', 'cell', 'activ'],\n",
       " ['gene', 'protein', 'network', 'cell', 'activ'],\n",
       " ['network', 'protein', 'gene', 'interact', 'activ'],\n",
       " ['network', 'gene', 'protein', 'interact', 'activ'],\n",
       " ['gene', 'network', 'protein', 'activ', 'cell'],\n",
       " ['gene', 'protein', 'network', 'sequenc', 'activ'],\n",
       " ['protein', 'gene', 'network', 'sequenc', 'interact'],\n",
       " ['gene', 'protein', 'network', 'sequenc', 'activ'],\n",
       " ['protein', 'network', 'gene', 'sequenc', 'activ'],\n",
       " ['gene', 'network', 'protein', 'cell', 'activ'],\n",
       " ['gene', 'protein', 'network', 'sequenc', 'cell'],\n",
       " ['gene', 'network', 'protein', 'cell', 'sequenc'],\n",
       " ['gene', 'cell', 'protein', 'network', 'express']]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5acf0c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#User Profiling\n",
    "\n",
    "df_userLibrary_explode = df_userLibrary.selectExpr(\"user_hash_id\",\"explode(user_library) AS paper_id\")\n",
    "df_userJoined_TfIdf = df_userLibrary_explode.join(df_rescaledCleanedData,df_userLibrary_explode.paper_id == df_rescaledCleanedData.paper_id, how=\"inner\").select(df_userLibrary_explode.user_hash_id,df_userLibrary_explode.paper_id,df_rescaledCleanedData.tf_idf_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2311125d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def addSparseVectors(v1, v2):\n",
    "    values = collections.defaultdict(float) # Initialize Dictionary with default value 0.0\n",
    "    \n",
    "    # Add values from v1 SparseVector\n",
    "    for i in range(v1.indices.size):\n",
    "        values[v1.indices[i]] += v1.values[i]\n",
    "    # Add values from v2 SParseVector\n",
    "    for i in range(v2.indices.size):\n",
    "        values[v2.indices[i]] += v2.values[i]\n",
    "    return Vectors.sparse(v1.size, dict(values))\n",
    "\n",
    "df_userprofile_tfidf = df_userJoined_TfIdf.selectExpr(\"user_hash_id\",\"tf_idf_vector\").rdd.reduceByKey(lambda x,y: addSparseVectors(x,y)).toDF().selectExpr(\"_1 AS user_hash_id\",\"_2 AS sum_tf_idf_vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b75f7724",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(user_hash_id='6931f7f79678cf72aae416ff7cb43bb1', sum_tf_idf_vector=SparseVector(1000, {0: 13.9931, 1: 23.287, 3: 9.3123, 4: 37.249, 5: 4.6555, 6: 4.6536, 7: 32.5708, 10: 9.2996, 11: 4.6492, 12: 23.2428, 13: 4.6467, 14: 41.8145, 18: 9.2734, 20: 4.633, 22: 4.6305, 23: 41.6692, 24: 4.6299, 26: 97.1893, 27: 9.2561, 28: 37.0147, 29: 4.6256, 31: 4.6238, 33: 4.6146, 34: 13.8384, 35: 4.6122, 36: 13.8293, 37: 23.0429, 38: 13.8257, 39: 9.2147, 41: 4.6044, 42: 9.2087, 47: 18.3839, 48: 9.192, 51: 13.7737, 52: 4.5889, 53: 4.5889, 55: 13.756, 56: 4.583, 57: 9.1601, 60: 13.7331, 62: 13.7243, 65: 4.5707, 67: 9.1298, 68: 4.5643, 70: 13.6809, 72: 173.1171, 74: 95.6219, 75: 36.4183, 76: 9.1034, 77: 4.5511, 78: 4.55, 79: 13.6483, 80: 9.0989, 81: 9.0977, 84: 4.5466, 86: 40.8787, 87: 18.166, 88: 4.5415, 89: 4.5409, 92: 27.2389, 93: 72.5921, 94: 31.7512, 95: 4.5353, 99: 18.1279, 100: 9.0628, 102: 9.0484, 104: 4.5236, 105: 9.045, 107: 9.0362, 110: 4.5153, 111: 13.5444, 113: 4.5148, 115: 9.023, 116: 9.023, 117: 36.0877, 118: 4.5104, 119: 4.5099, 120: 4.5093, 122: 4.5066, 123: 9.0088, 124: 4.5033, 127: 13.5035, 128: 17.9895, 131: 125.806, 132: 8.9861, 133: 13.476, 134: 8.9786, 136: 4.4877, 139: 17.9423, 140: 8.9648, 141: 4.4808, 142: 4.4808, 144: 4.4797, 145: 4.4765, 146: 8.9531, 147: 40.2794, 148: 22.3696, 149: 31.2769, 150: 13.4028, 152: 13.3981, 154: 8.9248, 156: 31.2184, 158: 22.2781, 159: 17.8225, 162: 22.2498, 165: 8.8917, 166: 22.2241, 168: 26.6658, 169: 4.4423, 171: 4.4412, 172: 8.8784, 173: 26.6322, 174: 62.1132, 176: 4.4326, 177: 17.7264, 179: 22.1504, 181: 4.4276, 182: 4.4276, 186: 39.8254, 188: 17.6962, 189: 8.8471, 191: 52.9866, 192: 4.4136, 193: 17.6523, 194: 17.6424, 196: 4.4086, 200: 8.8064, 201: 4.3998, 203: 21.9915, 204: 30.7812, 205: 8.7927, 207: 8.7771, 208: 17.5446, 210: 30.6794, 214: 17.4719, 215: 17.4643, 216: 34.9173, 217: 34.9059, 220: 30.5196, 221: 8.7171, 223: 21.788, 225: 8.7096, 226: 4.3543, 228: 4.3478, 229: 21.7227, 230: 21.7134, 231: 4.3372, 232: 4.3367, 234: 4.3335, 235: 12.9977, 236: 4.3307, 237: 8.6578, 238: 4.3285, 239: 4.3271, 242: 12.9785, 245: 8.6496, 246: 17.2811, 249: 34.5406, 251: 17.2631, 254: 17.2559, 255: 21.5699, 256: 4.3108, 257: 30.1571, 258: 17.229, 259: 4.305, 260: 12.9084, 262: 4.3015, 263: 34.3658, 265: 4.2922, 266: 8.5721, 267: 8.5721, 268: 12.849, 269: 4.2826, 271: 8.5643, 273: 12.8373, 274: 8.5565, 276: 17.1112, 277: 4.2778, 278: 4.2761, 280: 21.3609, 281: 4.2705, 282: 4.27, 283: 38.4226, 284: 4.2687, 285: 12.8037, 287: 17.0493, 289: 21.2903, 290: 8.5153, 291: 12.7564, 292: 4.2471, 293: 101.8495, 295: 80.5752, 297: 12.7199, 299: 4.2362, 300: 8.4708, 301: 12.7062, 304: 16.9151, 306: 21.1335, 307: 16.9019, 310: 4.2193, 311: 8.4362, 313: 16.8675, 314: 8.4224, 315: 8.4183, 316: 21.0417, 317: 12.6141, 319: 12.5949, 320: 16.7916, 321: 4.1943, 322: 8.3878, 323: 12.5769, 327: 41.8676, 328: 4.1868, 329: 29.299, 331: 12.5567, 332: 4.184, 334: 20.9062, 335: 8.3609, 336: 20.9003, 337: 16.7139, 338: 4.1781, 339: 29.2274, 344: 8.3243, 345: 4.161, 346: 66.5696, 347: 4.1594, 348: 20.7953, 351: 12.4737, 352: 4.1552, 353: 4.1541, 354: 33.2172, 356: 8.3013, 358: 16.5934, 360: 20.7284, 361: 157.5214, 362: 4.1453, 363: 20.6962, 366: 8.2642, 369: 4.1302, 371: 4.1206, 374: 4.1136, 375: 8.2271, 376: 37.0187, 377: 24.6637, 378: 8.2176, 379: 28.7564, 380: 20.5366, 381: 8.2066, 383: 8.2008, 385: 32.7945, 386: 24.5915, 387: 8.1928, 388: 8.1914, 390: 4.0917, 391: 28.6421, 392: 8.1713, 394: 40.8456, 395: 8.167, 396: 20.4068, 398: 20.4014, 399: 4.0792, 401: 40.7638, 402: 8.1478, 403: 138.4888, 405: 16.2675, 406: 4.0665, 408: 36.5955, 409: 4.0648, 410: 28.4435, 411: 4.063, 412: 16.22, 414: 4.0488, 416: 32.3793, 420: 40.3782, 421: 4.0375, 422: 36.3128, 423: 8.0634, 424: 12.0931, 426: 56.2882, 427: 12.0597, 428: 76.3657, 430: 52.1592, 431: 4.0106, 433: 4.0083, 434: 12.0099, 435: 116.0866, 436: 32.0186, 437: 4.0, 438: 23.9864, 439: 11.9912, 440: 7.9909, 441: 3.9925, 442: 11.9707, 443: 3.987, 444: 3.9818, 445: 23.887, 446: 11.9329, 448: 15.9041, 449: 7.9514, 450: 7.9482, 451: 23.8427, 452: 11.9175, 455: 35.7039, 456: 3.9655, 460: 31.6609, 463: 11.8531, 465: 15.7668, 466: 3.9389, 467: 3.9374, 468: 11.8112, 469: 7.8692, 470: 7.8649, 471: 11.7863, 472: 7.857, 473: 66.7426, 474: 3.9251, 475: 3.9209, 476: 54.8667, 477: 15.6714, 478: 11.7363, 479: 19.5531, 480: 3.9094, 482: 39.0254, 483: 7.7968, 484: 11.6907, 485: 35.0668, 487: 7.7832, 489: 11.6703, 491: 23.3336, 492: 3.8866, 493: 23.2967, 494: 11.644, 495: 27.1591, 496: 3.8796, 497: 19.3819, 498: 814.0419, 500: 3.8703, 502: 3.8654, 506: 3.86, 507: 57.8913, 508: 212.096, 509: 11.5587, 510: 7.7046, 511: 3.852, 512: 19.2291, 515: 7.6816, 516: 3.8408, 517: 3.8394, 518: 26.86, 520: 7.6726, 521: 7.6715, 522: 11.5064, 523: 7.671, 524: 3.8352, 528: 153.1858, 529: 34.4097, 530: 7.6444, 531: 57.3124, 532: 26.7343, 533: 3.8173, 535: 30.501, 536: 30.4641, 537: 15.2169, 539: 22.8044, 541: 15.1932, 542: 3.7972, 544: 11.3861, 546: 3.7924, 547: 34.1295, 549: 3.7858, 550: 22.7004, 552: 7.5652, 553: 22.6893, 554: 26.4653, 555: 7.5615, 556: 22.6593, 557: 26.423, 558: 7.5447, 559: 30.1476, 560: 124.1704, 561: 3.762, 562: 15.0479, 563: 33.8553, 564: 3.7604, 565: 18.7917, 566: 75.1412, 567: 97.6702, 569: 22.51, 570: 3.7478, 571: 29.9725, 572: 3.7466, 574: 3.7352, 575: 18.6445, 576: 7.4573, 577: 11.1777, 578: 3.7179, 579: 37.1794, 580: 3.716, 581: 48.2979, 582: 3.715, 583: 51.9751, 584: 3.7118, 585: 3.7113, 586: 37.1054, 587: 11.1316, 589: 11.1309, 591: 7.4172, 592: 7.4162, 593: 3.7074, 594: 7.4132, 595: 11.1059, 596: 36.9857, 597: 36.9857, 598: 3.6983, 599: 25.8832, 600: 3.6971, 601: 3.6945, 602: 7.3836, 603: 3.6894, 604: 18.4445, 605: 22.1262, 606: 3.6824, 607: 29.4252, 609: 29.4043, 611: 3.6751, 612: 220.4041, 613: 3.6727, 614: 33.033, 615: 21.9796, 616: 14.6465, 617: 14.6344, 618: 25.6004, 620: 29.2334, 621: 7.3014, 622: 7.2968, 623: 21.8792, 624: 7.2912, 625: 72.9124, 626: 18.2051, 627: 3.6374, 628: 7.2679, 630: 7.2597, 631: 7.2574, 634: 43.4177, 635: 3.6172, 636: 7.2309, 637: 18.0773, 638: 144.5824, 639: 3.6121, 640: 14.4431, 641: 3.6108, 642: 46.845, 644: 28.7802, 646: 7.1889, 647: 28.7277, 648: 7.1736, 649: 43.0341, 650: 3.5816, 651: 32.2327, 652: 14.3213, 653: 46.5107, 654: 35.7732, 655: 50.0734, 657: 3.5743, 658: 14.2947, 659: 32.1457, 661: 7.1388, 662: 42.8173, 663: 17.8289, 664: 3.5658, 665: 7.1269, 666: 7.1218, 667: 21.3476, 669: 10.6624, 670: 7.0791, 671: 3.534, 672: 28.2701, 673: 14.1318, 674: 7.056, 675: 10.5742, 677: 28.1119, 678: 14.0535, 679: 24.5937, 680: 14.0479, 681: 10.522, 682: 3.5029, 683: 45.5305, 684: 10.4987, 685: 24.4955, 686: 27.96, 687: 6.9848, 688: 34.8691, 690: 48.7098, 691: 3.4785, 692: 6.9457, 693: 3.4725, 694: 3.4698, 696: 6.9234, 697: 6.9176, 698: 20.746, 699: 13.8223, 700: 34.4988, 701: 154.9558, 702: 27.5372, 703: 58.5101, 706: 41.2249, 707: 10.3062, 708: 34.3205, 709: 30.8268, 710: 3.423, 711: 20.5015, 712: 6.8298, 713: 10.2425, 714: 10.2381, 715: 64.8312, 716: 17.0317, 717: 6.8087, 718: 13.6102, 719: 44.198, 720: 47.5099, 721: 16.9491, 722: 6.7764, 723: 10.1625, 724: 27.0943, 725: 3.3783, 726: 57.4189, 727: 23.6209, 728: 6.7457, 729: 10.1133, 730: 10.1075, 731: 6.7376, 733: 20.2045, 734: 23.5367, 735: 10.0845, 736: 47.0466, 737: 13.4219, 738: 3.3549, 739: 3.3544, 740: 10.0561, 741: 6.6969, 742: 6.6965, 744: 23.3817, 745: 13.3556, 746: 23.3474, 747: 6.667, 748: 6.6656, 750: 19.9817, 751: 26.6182, 752: 6.6515, 753: 23.2722, 754: 9.9508, 755: 6.6279, 756: 13.2539, 757: 49.697, 758: 19.805, 759: 6.5987, 760: 23.0864, 761: 13.1825, 762: 16.4643, 763: 39.5086, 764: 121.7942, 765: 42.7611, 766: 13.1527, 767: 151.1307, 769: 19.7069, 770: 6.5642, 771: 22.9199, 773: 71.9781, 774: 39.2399, 775: 16.3492, 776: 13.0736, 777: 16.3239, 778: 52.1888, 779: 26.0756, 780: 22.8008, 781: 9.7634, 782: 61.7255, 783: 48.719, 784: 12.9899, 785: 35.6882, 786: 16.2158, 787: 51.7579, 788: 25.8765, 789: 16.1652, 790: 22.6292, 791: 9.6909, 793: 100.1158, 794: 25.8266, 795: 19.3346, 796: 38.597, 797: 41.7706, 799: 19.2716, 800: 12.8287, 801: 6.412, 802: 3.2042, 803: 35.2397, 804: 12.8073, 805: 9.5944, 806: 6.3711, 807: 19.1003, 808: 22.2776, 809: 15.8686, 810: 34.9093, 811: 6.346, 812: 22.208, 813: 3.172, 814: 9.5078, 815: 9.5074, 817: 9.453, 818: 18.8976, 819: 3.1489, 820: 75.57, 821: 9.4421, 822: 28.301, 823: 37.6896, 824: 18.8365, 826: 90.7864, 827: 18.7488, 829: 352.4709, 830: 24.9125, 832: 24.7942, 833: 3.0864, 834: 27.7696, 835: 9.2463, 836: 49.2403, 837: 126.1355, 838: 12.2965, 839: 9.2201, 840: 33.8026, 841: 27.6007, 842: 21.4609, 843: 52.1062, 844: 3.0626, 845: 24.4866, 846: 58.1338, 847: 42.78, 848: 21.3864, 849: 9.145, 850: 12.1731, 851: 6.075, 852: 15.1793, 853: 15.165, 855: 21.2083, 856: 30.2901, 858: 36.3332, 859: 15.1227, 860: 24.1825, 861: 18.1081, 862: 3.0147, 863: 12.0583, 864: 15.0576, 865: 12.0368, 866: 11.9888, 867: 35.9419, 869: 14.9608, 870: 2.9843, 871: 11.9333, 872: 35.7872, 873: 65.5656, 874: 32.7024, 875: 20.7786, 876: 14.8401, 877: 23.7273, 878: 50.3651, 879: 41.4235, 880: 26.5836, 881: 23.6124, 882: 5.8775, 884: 5.8567, 885: 2.9277, 886: 32.1922, 887: 14.5954, 888: 58.2129, 890: 40.7058, 891: 63.901, 892: 46.4682, 894: 23.1642, 895: 57.8714, 896: 22.9445, 897: 45.8704, 898: 22.8762, 901: 8.5206, 902: 5.6796, 903: 8.5135, 905: 8.4532, 906: 16.8158, 907: 72.6684, 908: 55.8909, 910: 30.6914, 911: 8.3648, 912: 44.4816, 913: 38.8672, 914: 49.8924, 915: 55.3842, 916: 19.3784, 917: 8.3033, 918: 8.2904, 919: 146.2777, 920: 13.7865, 921: 22.0569, 922: 11.0197, 923: 283.6513, 924: 22.0063, 925: 16.4974, 926: 10.9922, 927: 2.741, 928: 101.3533, 929: 13.6741, 930: 19.1347, 931: 62.6805, 932: 2.7231, 933: 48.9309, 934: 16.2591, 935: 35.1415, 936: 62.0952, 937: 61.9741, 938: 40.4152, 939: 10.7671, 940: 32.1521, 941: 18.6719, 942: 7.9942, 943: 5.3208, 944: 5.3154, 945: 47.4293, 946: 763.2826, 947: 20.9493, 948: 28.6872, 949: 192.9502, 950: 2.5987, 951: 72.6362, 952: 10.3654, 953: 59.575, 954: 7.7489, 955: 33.534, 956: 59.1278, 957: 74.4137, 958: 7.69, 959: 40.6407, 960: 12.6865, 961: 20.2608, 962: 70.6473, 963: 55.5069, 964: 206.2529, 965: 27.6623, 966: 12.529, 967: 5.0104, 968: 39.958, 969: 9.9796, 970: 9.9019, 971: 68.7158, 972: 63.7748, 973: 14.706, 974: 34.2963, 975: 12.1494, 976: 216.144, 977: 21.8419, 978: 67.8234, 979: 70.1084, 980: 4.8185, 981: 23.9896, 982: 52.3231, 983: 47.4398, 984: 97.241, 985: 243.5546, 986: 23.6071, 987: 7.0669, 988: 30.5977, 989: 95.7551, 990: 13.968, 991: 34.8969, 992: 60.2601, 993: 46.3429, 994: 142.9002, 995: 50.4784, 996: 13.6805, 997: 81.9987, 998: 11.3758, 999: 29.5293}))]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_userprofile_tfidf.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c72a9c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
