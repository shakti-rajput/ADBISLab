{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d3de4748",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext,SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "import csv\n",
    "from collections import Counter\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fd1d87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext()\n",
    "spark = SparkSession.builder.appName('Experiment1').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4252a37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "userLibraryRdd = sc.textFile(\"Datasets/users_libraries.txt\")\n",
    "userLibraryRdd = userLibraryRdd.map(lambda line: line.split(\";\")).map(lambda line: (line[0],list(map(int,line[1].split(\",\")))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7df967b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processPaperCsv(line):\n",
    "    paperCsv = csv.reader([line.replace(\"\\0\", \"\")], delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
    "    paperCsvList = next(paperCsv)\n",
    "    return paperCsvList[0], paperCsvList[14]\n",
    "\n",
    "paperCsvRdd = sc.textFile(\"Datasets/papers.csv\")\n",
    "paperCsvRdd = paperCsvRdd.map(processPaperCsv).filter(lambda x: (x[1] != \"\" and x[1] != \" \")).map(lambda x: (int(x[0]),x[1].split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66cd7c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWords = sc.textFile(\"Datasets/stopwords_en.txt\")\n",
    "stopWordsBroadcast = sc.broadcast(stopWords.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9dbc1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeStopWords(wordList):\n",
    "    abstractwordsList = wordList.copy()\n",
    "    for a in wordList:\n",
    "        if ((a in stopWordsBroadcast.value) or a == \"\" or a == \" \"):\n",
    "            abstractwordsList.remove(a)\n",
    "    return abstractwordsList\n",
    "\n",
    "userLibraryJoinPaperRdd = userLibraryRdd.flatMapValues(lambda x: x).map(lambda x: (x[1],x[0])).join(paperCsvRdd)\n",
    "userLibraryJoinPaperRdd = userLibraryJoinPaperRdd.map(lambda x: (x[1][0],x[1][1]))\n",
    "userLibraryJoinPaperRdd = userLibraryJoinPaperRdd.flatMapValues(lambda x:x).groupByKey().mapValues(list)\n",
    "userLibraryJoinPaperWithoutStopWordsRdd = userLibraryJoinPaperRdd.mapValues(removeStopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ecff4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findTopMostFrequentWords(x):\n",
    "    CounterList = Counter(x)\n",
    "    topTenMostFrequentWordWithCount = CounterList.most_common(10)\n",
    "    topTenMostFrequentWord = [word for word, word_count in topTenMostFrequentWordWithCount]\n",
    "    return topTenMostFrequentWord\n",
    "\n",
    "frequentlyOccuringWordList = userLibraryJoinPaperWithoutStopWordsRdd.mapValues(findTopMostFrequentWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f522b2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#frequentlyOccuringWordList.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad71a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateCsvLine(data):\n",
    "    csvLineData = data[0] + \",\" + (','.join(str(d) for d in data[1]))\n",
    "    return csvLineData\n",
    "\n",
    "frequentlyOccuringWordListFile = frequentlyOccuringWordList.map(CreateCsvLine)\n",
    "frequentlyOccuringWordListFile.saveAsTextFile(\"Datasets/Top10WordsForEachUser_RDD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61418db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#frequentlyOccuringWordListFile.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a61bcf8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of (distinct) user: 28416\n",
      "Number of (distinct) items: 172079\n",
      "Number of ratings: 828481\n"
     ]
    }
   ],
   "source": [
    "#Ex1.4\n",
    "\n",
    "userLibrayFMVRdd =userLibraryRdd.flatMapValues(lambda x:x)\n",
    "\n",
    "#a\n",
    "noOfDistinctUsers = userLibrayFMVRdd.keys().distinct().count()\n",
    "noOfDistinctItems = userLibrayFMVRdd.values().distinct().count()\n",
    "noOfRatings = userLibrayFMVRdd.values().count()\n",
    "\n",
    "print(\"Number of (distinct) user:\" ,noOfDistinctUsers)\n",
    "print(\"Number of (distinct) items:\" ,noOfDistinctItems)\n",
    "print(\"Number of ratings:\" ,noOfRatings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13f541ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#b,c,d,e\n",
    "\n",
    "ratingsList = userLibraryRdd.map(lambda x: (x[0],len(x[1]))).map(lambda x: x[1])\n",
    "minNoOfRatingUserHasGiven = ratingsList.min()\n",
    "#minNoOfRatingUserHasGiven = userLibraryRdd.map(lambda x: (x[0],len(x[1]))).sortBy(lambda x: x[1], ascending=True).map(lambda x: x[1]).first()\n",
    "maxNoOfRatingUserHasGiven = ratingsList.max()\n",
    "#maxNoOfRatingUserHasGiven = userLibraryRdd.map(lambda x: (x[0],len(x[1]))).sortBy(lambda x: x[1], ascending=False).map(lambda x: x[1]).first()\n",
    "avgNumberOfRatingUserGave = noOfRatings/noOfDistinctUsers\n",
    "standardDeviationOfRating = ratingsList.stdev()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "940bc13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min number of ratings a user has given: 1\n",
      "Max number of ratings a user has given: 1922\n",
      "Average number of ratings of users: 29.155440596846848\n",
      "Standard deviation for ratings of users: 81.1751761366871\n"
     ]
    }
   ],
   "source": [
    "print(\"Min number of ratings a user has given:\",minNoOfRatingUserHasGiven)\n",
    "print(\"Max number of ratings a user has given:\",maxNoOfRatingUserHasGiven)\n",
    "print(\"Average number of ratings of users:\",avgNumberOfRatingUserGave)\n",
    "print(\"Standard deviation for ratings of users:\",standardDeviationOfRating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a7cd49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "userLibraryReduceByPaperIdRdd = userLibrayFMVRdd.map(lambda x: (x[1],1)).reduceByKey(lambda x,y: x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ec81573",
   "metadata": {},
   "outputs": [],
   "source": [
    "#f,g,h,i\n",
    "\n",
    "ratingsListByPaperId = userLibraryReduceByPaperIdRdd.map(lambda x: x[1])\n",
    "minNoOfRatingItemHasReceived = ratingsListByPaperId.min()\n",
    "maxNoOfRatingItemHasReceived = ratingsListByPaperId.max()\n",
    "avgNumberOfRatingOfItems = noOfRatings/noOfDistinctItems\n",
    "standardDeviationOfRItem = ratingsListByPaperId.stdev()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "376bcbd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min number of ratings an item has received: 3\n",
      "Max number of ratings an item has received: 924\n",
      "Average number of ratings of items: 4.81453867119172\n",
      "Standard deviation for ratings of items: 5.477802292314525\n"
     ]
    }
   ],
   "source": [
    "print(\"Min number of ratings an item has received:\",minNoOfRatingItemHasReceived)\n",
    "print(\"Max number of ratings an item has received:\",maxNoOfRatingItemHasReceived)\n",
    "print(\"Average number of ratings of items:\",avgNumberOfRatingOfItems)\n",
    "print(\"Standard deviation for ratings of items:\",standardDeviationOfRItem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b99d5b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "userLibrarySchema = StructType([\n",
    "    StructField(\"user_hash_id\",StringType(),False),\n",
    "    StructField(\"user_library\",StringType(),False)\n",
    "])\n",
    "df_userLibrary = spark.read.csv(\"Datasets/users_libraries.txt\", sep = \";\", header = False, schema = userLibrarySchema)\n",
    "df_userLibrary = df_userLibrary.selectExpr(\"user_hash_id\",\"split(user_library,',') AS user_library\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba22f740",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_userLibrary.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d79c288",
   "metadata": {},
   "outputs": [],
   "source": [
    "papersCsvSchema = StructType([\n",
    "    StructField(\"paper_id\",StringType(),False),\n",
    "    StructField(\"type\",StringType(),False),\n",
    "    StructField(\"journal\",StringType(),False),\n",
    "    StructField(\"book_title\",StringType(),False),\n",
    "    StructField(\"series\",StringType(),False),\n",
    "    StructField(\"publisher\",StringType(),False),\n",
    "    StructField(\"pages\",StringType(),False),\n",
    "    StructField(\"volume\",StringType(),False),\n",
    "    StructField(\"number\",StringType(),False),\n",
    "    StructField(\"year\",StringType(),False),\n",
    "    StructField(\"month\",StringType(),False),\n",
    "    StructField(\"postedat\",StringType(),False),\n",
    "    StructField(\"address\",StringType(),False),\n",
    "    StructField(\"title\",StringType(),False),\n",
    "    StructField(\"abstract\",StringType(),False),\n",
    "])\n",
    "df_paperCsv = spark.read.csv(\"Datasets/papers.csv\", sep = \",\", header = False, schema = papersCsvSchema, quote = '\"')\n",
    "df_paperCsv = df_paperCsv.selectExpr(\"paper_id\",\"split(replace(abstract,'\\\"',''),' ') AS abstract\")\n",
    "df_paperCsv = df_paperCsv.na.drop(subset=[\"abstract\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "695f3941",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_paperCsv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc5df243",
   "metadata": {},
   "outputs": [],
   "source": [
    "userLibraryExplode = df_userLibrary.select(df_userLibrary.user_hash_id,explode(df_userLibrary.user_library).alias(\"paper_id\"))\n",
    "df_userLibraryJoinPaperCsv = df_paperCsv.join(userLibraryExplode,df_paperCsv.paper_id == userLibraryExplode.paper_id, how=\"inner\").select(userLibraryExplode.user_hash_id,userLibraryExplode.paper_id,df_paperCsv.abstract)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60921091",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_userLibraryJoinPaperCsv = df_userLibraryJoinPaperCsv.select(df_userLibraryJoinPaperCsv.user_hash_id,explode(df_userLibraryJoinPaperCsv.abstract).alias(\"abstract\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1c9f5467",
   "metadata": {},
   "outputs": [],
   "source": [
    "useless_words = ['',' ','\"']\n",
    "df_userLibraryJoinPaperCsvWithoutStopWords = df_userLibraryJoinPaperCsv[~df_userLibraryJoinPaperCsv[\"abstract\"].isin(stopWordsBroadcast.value)]\n",
    "df_userLibraryJoinPaperCsvWithoutStopWords = df_userLibraryJoinPaperCsvWithoutStopWords[~df_userLibraryJoinPaperCsvWithoutStopWords[\"abstract\"].isin(useless_words)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6239c5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_userLibraryJoinPaperCsvWithoutStopWordsCount = df_userLibraryJoinPaperCsvWithoutStopWords.groupBy(\"user_hash_id\",\"abstract\").count().withColumnRenamed(\"count\", \"word_count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "543210eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "userWords_window = Window.partitionBy(df_userLibraryJoinPaperCsvWithoutStopWordsCount.user_hash_id).orderBy(col(\"word_count\").desc())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0f8e536a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_userLibraryJoinPaperCsvWithoutStopWordsRank = df_userLibraryJoinPaperCsvWithoutStopWordsCount.withColumn(\"word_rank\",rank().over(userWords_window))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f939a18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topFrequentWordsPerUser = df_userLibraryJoinPaperCsvWithoutStopWordsRank.filter(df_userLibraryJoinPaperCsvWithoutStopWordsRank[\"word_rank\"]<11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8673a1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groupedTop10FrequentWordsPerUser = df_topFrequentWordsPerUser.groupBy(\"user_hash_id\").agg(collect_list(\"abstract\")).withColumnRenamed(\"collect_list(abstract)\", \"abstract_word_list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92043a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groupedTop10FrequentWordsPerUser.write.save(\"Datasets/Top10WordsForEachUser_DF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d353395d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
